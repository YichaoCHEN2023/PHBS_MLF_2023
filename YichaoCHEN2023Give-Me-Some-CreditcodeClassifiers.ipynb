{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C value: 0.0001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib\n",
    "from distutils.version import LooseVersion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0],\n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.8,\n",
    "                    color=colors[idx],\n",
    "                    marker=markers[idx],\n",
    "                    label=cl,\n",
    "                    edgecolor='black')\n",
    "    # highlight test examples\n",
    "    if test_idx:\n",
    "        # plot all examples\n",
    "        X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "\n",
    "        if LooseVersion(matplotlib.__version__) < LooseVersion('0.3.4'):\n",
    "            plt.scatter(X_test[:, 0],\n",
    "                        X_test[:, 1],\n",
    "                        c='',\n",
    "                        edgecolor='black',\n",
    "                        alpha=1.0,\n",
    "                        linewidth=1,\n",
    "                        marker='o',\n",
    "                        s=100,\n",
    "                        label='test set')\n",
    "        else:\n",
    "            plt.scatter(X_test[:, 0],\n",
    "                        X_test[:, 1],\n",
    "                        c='none',\n",
    "                        edgecolor='black',\n",
    "                        alpha=1.0,\n",
    "                        linewidth=1,\n",
    "                        marker='o',\n",
    "                        s=100,\n",
    "                        label='test set')\n",
    "\n",
    "        # 按间距中的绿色按钮以运行脚本。\n",
    "def bestCofLR(X,y):\n",
    "    log_reg = LogisticRegression()\n",
    "\n",
    "    # 定义要尝试的 C 值\n",
    "    param_grid = {'C': [0.0001,0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "    # 使用 Grid Search 进行参数搜索\n",
    "    grid_search = GridSearchCV(log_reg, param_grid, cv=5)\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # 输出最佳的 C 值\n",
    "    best_C = grid_search.best_params_['C']\n",
    "    print(\"Best C value:\", best_C)\n",
    "    return grid_search.best_estimator_\n",
    "def bestGammaofSVM(X,y):\n",
    "    # 定义支持向量机模型\n",
    "    svm = SVC(kernel='linear')\n",
    "\n",
    "    # 定义要尝试的 gamma 值\n",
    "    param_grid = {'C': [ 0.01, 0.1, 1,10]}\n",
    "\n",
    "    # 使用 Grid Search 进行参数搜索\n",
    "    grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # 输出最佳的 gamma 值\n",
    "    best_C = grid_search.best_params_['C']\n",
    "    print(\"Best C value:\", best_C)\n",
    "    return grid_search.best_estimator_\n",
    "def bestDepthofDT(X,y):\n",
    "    # 定义决策树模型\n",
    "    tree = DecisionTreeClassifier()\n",
    "\n",
    "    # 定义要尝试的树的深度值\n",
    "    param_grid = {'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "\n",
    "    # 使用 Grid Search 进行参数搜索\n",
    "    grid_search = GridSearchCV(tree, param_grid, cv=5)\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # 输出最佳的树的深度值\n",
    "    best_depth = grid_search.best_params_['max_depth']\n",
    "    print(\"Best tree depth:\", best_depth)\n",
    "    return grid_search.best_estimator_\n",
    "if __name__ == '__main__':\n",
    "    df = pd.read_csv(r'D:\\大学文件\\No.8_2023-2024学年第二学期\\机器学习\\Kaggle-Give-Me-Some-Data\\cs-training.csv')\n",
    "    # pd.set_option('display.max_columns', None)\n",
    "    # pd.set_option('display.max_rows', None)\n",
    "    for column in list(df.columns[df.isnull().sum() > 0]):\n",
    "        mean_val = df[column].mean()\n",
    "        df[column].fillna(mean_val, inplace=True)\n",
    "    y_train = df['SeriousDlqin2yrs'].to_numpy()\n",
    "    X_train = df.drop(df.columns[[0, 1]], axis=1).values\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X_train)\n",
    "    X_train_std = sc.transform(X_train)\n",
    "    X_new= SelectFromModel(LogisticRegression(penalty=\"l1\", C=0.1,solver='liblinear'),max_features=2).fit_transform(X_train, y_train)\n",
    "\n",
    "    LR=bestCofLR(X_new,y_train)\n",
    "    #SVM=bestGammaofSVM(X_new,y_train)\n",
    "    SVM = SVC(kernel='linear', C=1)\n",
    "    SVM=SVM.fit(X_new, y_train)\n",
    "    DT=bestDepthofDT(X_new,y_train)\n",
    "\n",
    "    plot_decision_regions(X=X_new, y=y_train,classifier=LR)\n",
    "    plt.xlabel('petal length [standardized]')\n",
    "    plt.ylabel('petal width [standardized]')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('images/03_01.png', dpi=300)\n",
    "    plt.show()\n",
    "    plot_decision_regions(X=X_new, y=y_train, classifier=SVM)\n",
    "    plt.xlabel('petal length [standardized]')\n",
    "    plt.ylabel('petal width [standardized]')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('images/03_01.png', dpi=300)\n",
    "    plt.show()\n",
    "    plot_decision_regions(X=X_new, y=y_train, classifier=DT)\n",
    "    plt.xlabel('petal length [standardized]')\n",
    "    plt.ylabel('petal width [standardized]')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('images/03_01.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
